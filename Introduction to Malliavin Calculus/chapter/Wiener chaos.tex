\chapter{Wiener chaos}

\begin{definition}[sigma algebra generated by a set of random variable]
$\mathcal{G} = \sigma(\{\sigma(w): w \in W \})$, where $W$ is a centered Gaussian family. 
\end{definition}

\begin{lemma}
\label{lemma:linear span is dense}
The linear span of $\{e^{w}: w \in W\}$ is a dense in $L^2(\Omega, \mathcal{G}, P)$. 
\end{lemma}

\begin{proof}
Using the similar technique as Lemma 4.3.2 (Page 50) in
\cite{StochasticDifferentialEquationsAnIntroductionwithApplications}. 

Due to \hyperref[theorem:zero is the only vector orthogonal to dense]
{Theorem \ref*{theorem:zero is the only vector orthogonal to dense}}, it suffices to prove that $\forall X \in L^2(\Omega, \mathcal{G}, P)$, if $X$ is orthogonal to $\{e^{w}: w \in W\}$, then $X \equiv 0$ almost surely. 

Select $X \in L^2(\Omega, \mathcal{G}, P)$, such that $\E[Xe^{W(h)}]=0, \forall h \in H$. $X$ is well defined, because $X = 0$ meets the requirement. 

So $\forall n \in \mathbb{N}$, 
$G_n(\lambda_1, \dots, \lambda_n) \coloneqq 
\E[X e^{\sum_{i=1}^{n} \lambda_i W(h_i) }] = 0$, 
$\forall \lambda_1, \dots, \lambda_n \in \mathbb{R}$ and 
$\forall h_1, \dots, h_n \in H$. 

Then we can extend $G_n$ to a larger domain, 
$G_n: \mathbb{C}^n \to \mathbb{C}$. Because $G_n$ is analytic function on $\mathbb{R}^n$, we know that $G \equiv 0$ on $\mathbb{C}^n$. 

Meanwhile, $\forall \varphi \in C_{0}^{\infty}(\mathbb{R}^n, \mathbb{R}^n)$, 
$\E[X\varphi(W(h_i), \dots, W(h_n))] \\
= (2\pi)^{-\frac{n}{2}} 
\int_{\mathbb{R}^n} \hat(\varphi)(y_1, \dots, y_n) G_n(iy_1, \dots, iy_n) dy_1\dots dy_n = 0$, 
where $\hat(\varphi)$ is Fourier transform of $\varphi$. 

Because of the above lemma, we know that $X = 0$ only. 
\end{proof}

\begin{definition}[n-th Wiener chaos]
Given $L^2(\Omega, \mathcal{G}, P)$
, its closed linear subspace $\mathcal{H}_n$ is called n-th Wiener chaos
if it is the linear span of 
$\{H_n(w): w(h) \in W, \lVert h \rVert_{H} = 1\}$. 
\end{definition}

\begin{lemma}
The space $\mathcal{H}_n$ and $\mathcal{H}_m$ are orthogonal, if $n \neq m$. 
\end{lemma}

\begin{proof}
$\forall X \in \mathcal{H}_n$, 
$\forall Y \in \mathcal{H}_m$, 
such that $X = H_n(W(h_1))$ and $Y = H_m(W(h_2))$, 
where $\lVert h_1 \rVert_{H} = 1$ 
and $\lVert h_2 \rVert_{H} = 1$. 

Applying moment generating function on $(X, Y)$, 
$\forall s, t \in \mathbb{R}$, 
we have $\E[e^{sX - \frac{s^2}{2}}e^{tY - \frac{t^2}{2}}] 
= e^{st\E[XY]}$. 

Applying $\frac{\partial^{m+n}}{\partial s^{n} \partial t^{m}}$ on both side at 
$s=0, t=0$, we can prove the result. 
\end{proof}

\begin{theorem}
Given a Hilbert space $L^2(\Omega, \mathcal{F}, P)$, $L^2(\Omega, \mathcal{F}, P) = \bigoplus_{n=0}^{\infty} \mathcal{H}_n$.  
\end{theorem}

\begin{proof}
Select $X \in L^2(\Omega, \mathcal{F}, P)$, 
such that $\forall n \in \mathbb{N}$, $\forall Y \in \mathcal{H}_n$, 
$\E[XY] = 0$. $X$ is well defined, because $X=0$ meets the requirements. It suffices to prove that $X = 0$ only. 

It is known that any polynomial can be treated as a finite linear combination of Hermite polynomial, 
and Taylor expansion of $e^x$. So $\E[X e^{t W(h)}] = 0, \forall t \in \mathbb{R}$ and $\lVert h \rVert_{H} = 1$. 

Therefore, from \hyperref[lemma:linear span is dense]
{Lemma \ref*{lemma:linear span is dense}}, $X = 0$ only. 
\end{proof}

%\begin{corollary}
%    $\forall X \in L^2(\Omega, \mathcal{F}, P)$
%    , $X = \sum_{n=0}^{\infty} \mathcal J_n(X)$, 
%    where $J_n : L^2(\Omega, \mathcal{F}, P) \to \mathcal{H}_n$.  
%\end{corollary}
%
%\begin{proof}
%    
%\end{proof}